{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of  BBT045_HMM_Homework.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leticiacastillon/appliedbioinformatics2020/blob/master/HMM_Homework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kUt2W7fIhWV",
        "colab_type": "text"
      },
      "source": [
        "# Instructions\n",
        "\n",
        "For this homework, your task is to build an HMM model for annotating S. cerevisiae.\n",
        "Please read through the instructions before you start, to best plan your work.\n",
        "\n",
        "The work is split up in:\n",
        "\n",
        "1. getting baseline results with the HMM-based tool [Augustus](http://bioinf.uni-greifswald.de/augustus/) \n",
        "2. reading a little reference material on HMM gene prediction\n",
        "3. building and training your HMM\n",
        "4. comparing with the baseline\n",
        "\n",
        "Parts 1 can be done after 2 and 3, though it's perhaps best to have the results ready\n",
        "and to look over them a bit.\n",
        "For the last 2 points, helper Python code is provided to make the job easier.\n",
        "\n",
        "## 1. Baseline Results\n",
        "\n",
        "**Note** This step can take some time (~30 min if the server isn't under heavy load).\n",
        "\n",
        "For this part, you will need to run Augustus on the server, where it's already installed.\n",
        "\n",
        "Grab a copy of the *S. cerevisiae* reference genome (from either the HMM or UNIX exercises).\n",
        "Then run Augustus as below (adjust if you've named your directories differently)\n",
        "\n",
        "```bash\n",
        "augustus data/S288C_reference_sequence_R64-2-1_20150113.fsa \\\n",
        "\t--species=saccharomyces_cerevisiae_S288C \\\n",
        "\t--progress=True > results/ref_annot_augustus.gff\n",
        "```\n",
        "\n",
        "The output will be a [GFF](https://www.ensembl.org/info/website/upload/gff3.html) file.\n",
        "It looks like this:\n",
        "\n",
        "```\n",
        "# Predicted genes for sequence number 1 on both strands\n",
        "# start gene g1\n",
        "ref|NC_001133|  AUGUSTUS        gene    1807    2169    1       -       .       g1\n",
        "ref|NC_001133|  AUGUSTUS        transcript      1807    2169    1       -       .       g1.t1\n",
        "ref|NC_001133|  AUGUSTUS        stop_codon      1807    1809    .       -       0       transcript_id \"g1.t1\"; gene_id \"g1\";\n",
        "ref|NC_001133|  AUGUSTUS        CDS     1810    2169    1       -       0       transcript_id \"g1.t1\"; gene_id \"g1\";\n",
        "ref|NC_001133|  AUGUSTUS        start_codon     2167    2169    .       -       0       transcript_id \"g1.t1\"; gene_id \"g1\";\n",
        "# protein sequence = [MVKLTSIAAGVAAIAATASATTTLAQSDERVNLVELGVYVSDIRAHLAQYYMFQAAHPTETYPVEVAEAVFNYGDFTT\n",
        "# MLTGIAPDQVTRMITGVPWYSSRLKPAISSALSKDGIYTIAN]\n",
        "# end gene g1\n",
        "```\n",
        "\n",
        "Augustus basically lists all found genes one after the other, with the various sections marked.\n",
        "It also gives the protein sequence as a comment.\n",
        "Columns to note are:\n",
        "\n",
        "1. seqID = chromosome ID\n",
        "3. type of feature\n",
        "4. start position of feature\n",
        "5. end pos. of feat.\n",
        "\n",
        "Extract the protein sequences into a FASTA file. This will be used to search your results against.\n",
        "\n",
        "```bash\n",
        "getAnnoFasta.pl results/ref_annot_augustus.gff\n",
        "```\n",
        "\n",
        "This will create a file called `results/ref_annot_augustus.aa`\n",
        "\n",
        "## 2. Literature\n",
        "\n",
        "Read at least the 2 references below (a few pages), to recap the concepts and to get maybe get a model as your starting point.\n",
        "\n",
        "Please very **briefly describe your chosen model**. Why did you or the authors chose the sates you did? Did the authors mention why they chose the probabilities they did? If you created your own model, how did you decide the probabilities?\n",
        "\n",
        "References:\n",
        "\n",
        "* Quick recap of gene annotation with HMMs, along with a simple example model \n",
        "  [What is a hidden Markov model?](https://www.nature.com/articles/nbt1004-1315)\n",
        "\n",
        "* Some lecture slides from the University of Waterloo (pages 1-14 cover models like we've discussed). \n",
        "  You could use the model on page 9 as a starting point\n",
        "  https://www.math.uwaterloo.ca/~aghodsib/courses/w05stat440/w05stat440-notes/feb27.pdf\n",
        "\n",
        "* Yet another article describing a number of HMM classes for sequence analysis\n",
        "  The model in 2.2. (Fig. 1) could also be a starting point\n",
        "  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2766791/\n",
        "\n",
        "\n",
        "## 3. Build and train your model\n",
        "\n",
        "The simple 2-state model from the lecture is provided for you as an example how to work with this Python package. Your task is to construct a more complex / realistic model based on either the literature review in 2 (or Google) or your own ideas.\n",
        "\n",
        "You can use whatever model you like as a starting point and make it as complex as you wish.\n",
        "Remember however that at the end, you're supposed to distinguish genes, so interpreting just\n",
        "a binary coding / non-coding annotation is tricky.\n",
        "\n",
        "Keep in mind that the training algorithms only converge to a local optimum and\n",
        "that the convergence criteria can be tweaked. \n",
        "Starting with different random seeds will also produce different results.\n",
        "\n",
        "The S. cerevisiae reference has 17 chromosomes. \n",
        "Ideally, you should **train on all of them**, but depending on the model complexity and parameters,\n",
        "this might take a lot of time. It's up to you how and what to compromise on.\n",
        "The important thing is that you implement the entire procedure for your model.\n",
        "\n",
        "You can save trained models: https://hmmlearn.readthedocs.io/en/latest/tutorial.html#saving-and-loading-hmm\n",
        "And in Google Colab you can connect (\"mount\") your Drive to the notebook environment,\n",
        "then you can save to it (the folder called \"drive/\").\n",
        "Otherwise **all files disappear** from the notebook environment once you disconnect.\n",
        "\n",
        "\n",
        "## 4. Compare you results with the baseline\n",
        "\n",
        "To test, it's **sufficient to annotate chromosome 1**\n",
        "\n",
        "You'll primarily be concerned with the length distribution of the proteins coded by the genes you identify with your model. It should be similar to the distribution of Augustust results (and real gene data).\n",
        "\n",
        "The **last step** involves blasting the protein sequences of your genes against a reference, provided you've found long enough proteins to search for. In that sense, this last part is **optional** since the important thing for you is to build a working model, regarldess how well you do against state-of-the-art software :)  For this, you can either use the Augustus FASTA created as baseline or a yeas proteome fetched from https://www.uniprot.org/ . See the last step here on how to blast sequences: https://mpbio-bbt015.github.io/gene-prediction-exercise.html\n",
        "\n",
        "\n",
        "**Note** that the function provided for you to extract gene positions requires\n",
        "a regular expression (pattern) that describes what a gene looks like given the hidden states\n",
        "you chose. If you have trouble adjusting it for your model, get in touch with us since regexes were\n",
        "not covered in the course. \n",
        "If you want to experiment, https://regex101.com/ is a great size that tests and analyzes regexes\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZ5t8RAzRuxx",
        "colab_type": "text"
      },
      "source": [
        "# Setup\n",
        "\n",
        "This setup section needs to be run every time you connect to this notebook, as the environment it runs in is volatile (no software you install or files you create will be saved, unless you transfer the latter to your Drive)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27CpJlmDTDsR",
        "colab_type": "text"
      },
      "source": [
        "Install packages:\n",
        "\n",
        "* [hmmlearn](https://hmmlearn.readthedocs.io/en/latest/index.html) \n",
        "* [Biopython](https://biopython.org/) - for working with bio sequences\n",
        "* gffutils - for parsing GFF files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W_VCOC0yPTC",
        "colab_type": "code",
        "outputId": "efa371a6-b7d4-4da2-eba8-cf316b5d4807",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        }
      },
      "source": [
        "%%bash\n",
        "\n",
        "pip install hmmlearn\n",
        "pip install biopython\n",
        "pip install gffutils"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting hmmlearn\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/7b/33f629a443a0671161c019e55c3f1b511c7e9fdce5ab8c8c3c33470eb939/hmmlearn-0.2.3-cp36-cp36m-manylinux1_x86_64.whl (363kB)\n",
            "Requirement already satisfied: scikit-learn>=0.16 in /usr/local/lib/python3.6/dist-packages (from hmmlearn) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.6/dist-packages (from hmmlearn) (1.18.1)\n",
            "Requirement already satisfied: scipy>=0.15 in /usr/local/lib/python3.6/dist-packages (from hmmlearn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.16->hmmlearn) (0.14.1)\n",
            "Installing collected packages: hmmlearn\n",
            "Successfully installed hmmlearn-0.2.3\n",
            "Collecting biopython\n",
            "  Downloading https://files.pythonhosted.org/packages/83/3d/e0c8a993dbea1136be90c31345aefc5babdd5046cd52f81c18fc3fdad865/biopython-1.76-cp36-cp36m-manylinux1_x86_64.whl (2.3MB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from biopython) (1.18.1)\n",
            "Installing collected packages: biopython\n",
            "Successfully installed biopython-1.76\n",
            "Collecting gffutils\n",
            "  Downloading https://files.pythonhosted.org/packages/87/d6/f893f14fd6cf1c9e758259f6e0f9ba1ae03370988d8f1a3ea8d790ca5b06/gffutils-0.10.1.tar.gz (1.5MB)\n",
            "Collecting pyfaidx>=0.5.5.2\n",
            "  Downloading https://files.pythonhosted.org/packages/d9/eb/bca4c916d2cde775b5127cef22f276142b01e89fc31fecd832ed996dc97e/pyfaidx-0.5.8.tar.gz\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from gffutils) (1.12.0)\n",
            "Collecting argh>=0.26.2\n",
            "  Downloading https://files.pythonhosted.org/packages/06/1c/e667a7126f0b84aaa1c56844337bf0ac12445d1beb9c8a6199a7314944bf/argh-0.26.2-py2.py3-none-any.whl\n",
            "Collecting argcomplete>=1.9.4\n",
            "  Downloading https://files.pythonhosted.org/packages/82/7d/455e149c28c320044cb763c23af375bd77d52baca041f611f5c2b4865cf4/argcomplete-1.11.1-py2.py3-none-any.whl\n",
            "Collecting simplejson\n",
            "  Downloading https://files.pythonhosted.org/packages/98/87/a7b98aa9256c8843f92878966dc3d8d914c14aad97e2c5ce4798d5743e07/simplejson-3.17.0.tar.gz (83kB)\n",
            "Requirement already satisfied: setuptools>=0.7 in /usr/local/lib/python3.6/dist-packages (from pyfaidx>=0.5.5.2->gffutils) (45.2.0)\n",
            "Requirement already satisfied: importlib-metadata<2,>=0.23; python_version == \"3.6\" in /usr/local/lib/python3.6/dist-packages (from argcomplete>=1.9.4->gffutils) (1.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata<2,>=0.23; python_version == \"3.6\"->argcomplete>=1.9.4->gffutils) (3.1.0)\n",
            "Building wheels for collected packages: gffutils, pyfaidx, simplejson\n",
            "  Building wheel for gffutils (setup.py): started\n",
            "  Building wheel for gffutils (setup.py): finished with status 'done'\n",
            "  Created wheel for gffutils: filename=gffutils-0.10.1-cp36-none-any.whl size=1608578 sha256=b16e31092746e41b485dbefad7f6a43bb472b3ee3c0e142668621fe3dd09067d\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/c8/8c/5b5edef863b51b00f822fd7783608ea7a09b4ab75b87226479\n",
            "  Building wheel for pyfaidx (setup.py): started\n",
            "  Building wheel for pyfaidx (setup.py): finished with status 'done'\n",
            "  Created wheel for pyfaidx: filename=pyfaidx-0.5.8-cp36-none-any.whl size=25051 sha256=2fe67f58aef3615be4f8898443368276d9acf562c4845ede269c3b158d9ca9bc\n",
            "  Stored in directory: /root/.cache/pip/wheels/58/ea/ee/59d4649b0fb82a0690bdeae834bc85891b306126bcc067e29f\n",
            "  Building wheel for simplejson (setup.py): started\n",
            "  Building wheel for simplejson (setup.py): finished with status 'done'\n",
            "  Created wheel for simplejson: filename=simplejson-3.17.0-cp36-cp36m-linux_x86_64.whl size=114202 sha256=2431c08c5c6db4ab8aa0b0c0bac79e3703512e4e0e975823ef88f4ffdfd69cc1\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/c0/83/dcd0339abb2640544bb8e0938aab2d069cef55e5647ce6e097\n",
            "Successfully built gffutils pyfaidx simplejson\n",
            "Installing collected packages: pyfaidx, argh, argcomplete, simplejson, gffutils\n",
            "Successfully installed argcomplete-1.11.1 argh-0.26.2 gffutils-0.10.1 pyfaidx-0.5.8 simplejson-3.17.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gi61QZrJTINC",
        "colab_type": "text"
      },
      "source": [
        "Download *S. cerevisiae* reference genome and put it in a directory called `data`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R63byp6J21qH",
        "colab_type": "code",
        "outputId": "c50dc235-7c7a-4877-a01a-ec474fdeed24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "%%bash\n",
        "\n",
        "wget --quiet https://downloads.yeastgenome.org/sequence/S288C_reference/genome_releases/S288C_reference_genome_Current_Release.tgz\n",
        "tar -xzvf S288C_reference_genome_Current_Release.tgz\n",
        "mv S288C_reference_genome_R64-2-1_20150113 data\n",
        "rm S288C_reference_genome_Current_Release.tgz"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "S288C_reference_genome_R64-2-1_20150113/\n",
            "S288C_reference_genome_R64-2-1_20150113/rna_coding_R64-2-1_20150113.fasta\n",
            "S288C_reference_genome_R64-2-1_20150113/NotFeature_R64-2-1_20150113.fasta\n",
            "S288C_reference_genome_R64-2-1_20150113/orf_coding_all_R64-2-1_20150113.fasta\n",
            "S288C_reference_genome_R64-2-1_20150113/other_features_genomic_R64-2-1_20150113.fasta\n",
            "S288C_reference_genome_R64-2-1_20150113/S288C_reference_sequence_R64-2-1_20150113.fsa\n",
            "S288C_reference_genome_R64-2-1_20150113/gene_association_R64-2-1_20150113.sgd\n",
            "S288C_reference_genome_R64-2-1_20150113/orf_trans_all_R64-2-1_20150113.fasta\n",
            "S288C_reference_genome_R64-2-1_20150113/saccharomyces_cerevisiae_R64-2-1_20150113.gff\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAb90N9jSJhX",
        "colab_type": "text"
      },
      "source": [
        "## Import packages and define some helper functions\n",
        "\n",
        "hmmlearn is popular and has good performance but it's slighly trickier to work with. It doesn't use labels for states or emissions, just their index in the model (e.g. emission 0, 1, 2.. regardless of labels A, T, C G). Below are 2 functions to translate back and forth from numbers to symbols.\n",
        "\n",
        "To extract genes from an annotation sequence (e.g. NNNCCCNNN), the approach here\n",
        "is to extract patterns assumed to be genes from the full annotation using regular expressions . A function for that is provided.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuYjvZtbyA1M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Python built-ins\n",
        "import re\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "# Installed packages\n",
        "import numpy as np\n",
        "from hmmlearn import hmm\n",
        "from Bio import SeqIO\n",
        "\n",
        "\n",
        "def translate_symbol_sequence_to_numbers(symbol_sequence: str, symbol_alphabet: list) -> list:\n",
        "    \"\"\"\n",
        "    Translate emission symbols to numbers so that the HMM model can work with them\n",
        "    \"\"\"\n",
        "    translation_table = {symbol_alphabet[i]: i \n",
        "                         for i in range(len(symbol_alphabet))}\n",
        "    return [translation_table[symbol] for symbol in symbol_sequence]\n",
        "\n",
        "\n",
        "def translate_numbers_to_symbol_sequence(number_sequence: list, symbol_alphabet: list) -> str:\n",
        "    \"\"\"\n",
        "    Translate HMM hidden state numbers into symbols\n",
        "    \"\"\"\n",
        "    symbols = [symbol_alphabet[x] for x in number_sequence]\n",
        "    return ''.join(symbols)\n",
        "\n",
        "\n",
        "def get_gene_start_and_stop_from_annotation(annotation: str, gene_pattern: str) -> list:\n",
        "    \"\"\"\n",
        "    Return a list of (start_pos, end_pos) pairs for found genes.\n",
        "\n",
        "    Needs a regular expression (gene_pattern) that describes what a gene looks like\n",
        "    in terms of hidden states.\n",
        "    \n",
        "    Example:   \n",
        "        gene_pattern = 'C+'   # a sequence which consists of at least one C\n",
        "        annotation = 'NNCCNCCN'\n",
        "        \n",
        "        returns [(2, 4), (5, 7)]\n",
        "    \"\"\"\n",
        "    gene_positions = []\n",
        "    for match in re.finditer(gene_pattern, annotation):\n",
        "        gene_positions.append(match.span())\n",
        "    return gene_positions\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8vijJd2SUUg",
        "colab_type": "text"
      },
      "source": [
        "# Example: The basic (2-state) model\n",
        "\n",
        "The `hmmlearn` package provides a few HMM model classes. The one matching the basic kind we've covered is the `MultinomialHMM`.\n",
        "\n",
        "Below is the same basic model we've seen in the lecture and exercise, provided to show how to use the package.\n",
        "\n",
        "Skim through the short hmmlearn [tutorial](\n",
        "https://hmmlearn.readthedocs.io/en/latest/tutorial.html) to fix some concepts if the code/comments below are confusing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIfov6hNyKHS",
        "colab_type": "code",
        "outputId": "e6a3838a-fa35-4c0a-d150-41208fa7e927",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "hidden_states = ['C', 'N']               # Called \"components\" in this package\n",
        "emission_labels = ['A', 'T', 'C', 'G']   # Called \"fatures\"\n",
        "\n",
        "# Maximum n. iterations performed during training.\n",
        "# The training will stop at this regardless of how close it is to convergence (i.e. best fit to data)\n",
        "# Increasing will increase chances of a better fit but will of course take longer\n",
        "MAX_N_BAUM_WELCH_ITERATIONS = 10\n",
        "\n",
        "# Create model object\n",
        "basic_model = hmm.MultinomialHMM(n_components = len(hidden_states),\n",
        "                                 n_iter = MAX_N_BAUM_WELCH_ITERATIONS)\n",
        "\n",
        "# Adjust its parameters\n",
        "basic_model.n_features = len(emission_labels)\n",
        "\n",
        "# Order of elements must match those in the component and features lists above\n",
        "basic_model.startprob_ = np.array([0.3, 0.7])\n",
        "basic_model.transmat_ = np.array([[0.995, 0.005],\n",
        "                                  [0.01,  0.99]])\n",
        "\n",
        "# The matrix is expected to be of shape (rows=states x cols=emissions)\n",
        "# Here it's transposed from the form used in lecture slides\n",
        "basic_model.emissionprob_ = np.array([[0.3, 0.1],\n",
        "                                      [0.3, 0.1],\n",
        "                                      [0.2, 0.4],\n",
        "                                      [0.2, 0.4]]).T\n",
        "\n",
        "# Preview\n",
        "basic_model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialHMM(algorithm='viterbi', init_params='ste', n_components=2,\n",
              "               n_iter=10, params='ste', random_state=None, startprob_prior=1.0,\n",
              "               tol=0.01, transmat_prior=1.0, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-Acda5tTlwE",
        "colab_type": "text"
      },
      "source": [
        "Load reference genome (full chromosome sequences):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQ9J2tGwUiqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ref_chromosomes = list(SeqIO.parse('data/S288C_reference_sequence_R64-2-1_20150113.fsa', 'fasta'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4v0zsVTJTuqi",
        "colab_type": "text"
      },
      "source": [
        "## Prepare training data\n",
        "\n",
        "`hmmlearn` wants training sequences to be columns in a matrix. So here we structure the chromosome sequences that way, also converting from symbolic to numeric representation. \n",
        "\n",
        "For more details: https://hmmlearn.readthedocs.io/en/latest/tutorial.html#multiple-sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX-uDnF5SUyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Include k chromosomes in training data\n",
        "training_chromosome_idx = [0, 1]\n",
        "\n",
        "trainig_data = np.concatenate(\n",
        "    [np.array(\n",
        "        translate_symbol_sequence_to_numbers(ref_chromosomes[k].seq, emission_labels)\n",
        "        ).reshape(-1, 1)  # makes it a column vector\n",
        "     for k in training_chromosome_idx]\n",
        ")\n",
        "\n",
        "trainig_lengths = [len(ref_chromosomes[k].seq) for k in training_chromosome_idx]\n",
        "\n",
        "# Test on chromosome 1\n",
        "test_data = np.array(\n",
        "    [translate_symbol_sequence_to_numbers(ref_chromosomes[0].seq, emission_labels)]\n",
        ").T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vs8KldRevNqP",
        "colab_type": "text"
      },
      "source": [
        "The ubiquitous [NumPy](https://numpy.org/devdocs/user/quickstart.html) package is used to work with matrices and vectors. It was created as an imitation of Matlab so some thing should be familiar. But if you want to change the code and you get stuck, let us know! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zYkzznkUL0p",
        "colab_type": "text"
      },
      "source": [
        "## Train model \n",
        "\n",
        "The `.fit()` function is used as below. We fix the random seed to get the same results between runs. This can be changed to see how the algorithm converges differently based on initialization.\n",
        "\n",
        "For more details: https://hmmlearn.readthedocs.io/en/latest/api.html#hmmlearn.base._BaseHMM.fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOv_QkqDSMTy",
        "colab_type": "code",
        "outputId": "f420fb36-b2da-495f-89ac-ab17faf0ba9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "t0 = time.time()    # this is just to measure execution time (nothing to do with hmmlearn)\n",
        "np.random.seed(42)  # Make this randomized procedure deterministic (reproducible)\n",
        "\n",
        "basic_model.fit(trainig_data, trainig_lengths)\n",
        "\n",
        "print(f'Training took {time.time() - t0} seconds')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training took 49.746464252471924 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPrIVnjqxroK",
        "colab_type": "text"
      },
      "source": [
        "## Annotate chromosome\n",
        "\n",
        "Use the trained model to annotate our test chromosome with C or N (coding or non-coding nucleobase). The `.predict()` function is used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-aQrt5JSE61",
        "colab_type": "code",
        "outputId": "e3b9a1e4-0a84-4755-d65e-ba0f3b31f469",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "annotation_numeric = basic_model.predict(test_data)  # numbers == hidden state number\n",
        "annotation = translate_numbers_to_symbol_sequence(annotation_numeric, hidden_states)\n",
        "\n",
        "# Preview first 100 annotated bases\n",
        "annotation[0:500]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCNCCCCCCCCCCCCCCCNNCCCCCCCNCCCCCCCCCCCCCCCCCCCCCCCCCCNCCCCCCCCCNCCCCCCCNCCCCCCCCCCCCCCCCCCCCCCNCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCNCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCNCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCNCCCCCCCCCCCCCCCCNCCCCCCCCCCCCCCCCCCCNCCCCNCCCCCCCCCNCCCNCCCCCCCCCCCCCCNCNCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCNCCCCCCCCCCCCCCCCCCNCCCCCCNCCCCCCCNCCCNCCCCCNNCCNCCCCCNCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCNCCCCCCCCCCCCCCCCCNNCCCCC'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PK2I2x0n3Yi",
        "colab_type": "text"
      },
      "source": [
        "Now let's **extract genes**\n",
        "\n",
        "In our very simple model, we know \"genes\" are stretches of coding bases (obviously wrong because a bunch of coding groups of bases like CCCNNCCC could be exons in the same gene).\n",
        "\n",
        "So we get the start and end positions (indices) for all such patterns of multiple 'C's."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Phe8BYIGn6hv",
        "colab_type": "code",
        "outputId": "7329c080-3a19-492d-c89d-d08c79695dfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "gene_positions = get_gene_start_and_stop_from_annotation(annotation, \n",
        "                                                         gene_pattern = 'C+')\n",
        "\n",
        "# Preview gene positions\n",
        "gene_positions[0:4]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 83), (84, 99), (101, 108), (109, 135)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjsEdEKnq0rz",
        "colab_type": "text"
      },
      "source": [
        "**Question** Do these positions resemble the Augustus results?\n",
        "\n",
        "**Not really** ! This model is simplistic and the training consistsed of only a few iterations over only 2 chromosomes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUXyO7BSqfj1",
        "colab_type": "text"
      },
      "source": [
        "## Inspect results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPye_xcUbMuy",
        "colab_type": "text"
      },
      "source": [
        "### Transcribe and translate found genes to protein sequences\n",
        "\n",
        "Let's see if we were able to recover protein-coding genes!\n",
        "We'll use the Biopython sequence manipulation functionality.\n",
        "\n",
        "Remember we're working with chromosome 1  (indexed with 0 in our collection since Python lists are 0-indexed).\n",
        "\n",
        "Biopython will warn you when it's given a sequence that can't be propely translated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QpeBnurpYM8",
        "colab_type": "code",
        "outputId": "5c859523-b1cc-4da1-ca20-951324593965",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "def translate_genes(gene_positions: list, dna_sequence) -> list:\n",
        "    aa_sequences = []\n",
        "    for gene_pos in gene_positions:\n",
        "        aa = dna_sequence[gene_pos[0] : gene_pos[1]].transcribe().translate()\n",
        "        aa_sequences.append(aa)\n",
        "    return aa_sequences\n",
        "\n",
        "aa_sequences = translate_genes(gene_positions, ref_chromosomes[0].seq)\n",
        "\n",
        "# Preview\n",
        "aa_sequences[0]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/Bio/Seq.py:2859: BiopythonWarning: Partial codon, len(sequence) not a multiple of three. Explicitly trim the sequence or add trailing N before translation. This may become an error in future.\n",
            "  BiopythonWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq('PHHTHTPTHHTTHHTTPTHTHPNTTLTQP*SNPGQPVSQLTLHYPASTRYPVPF...*HT', HasStopCodon(ExtendedIUPACProtein(), '*'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ok4-oK0r7RN",
        "colab_type": "text"
      },
      "source": [
        "### Look at the protein length distribution\n",
        "\n",
        "(FYI: We're sneaking in the `pandas` package (already installed in Colab), which has become the standard Python package for data analysis.\n",
        "It's very similar to R's `tidyverse` and `data.table`. But here it's just used for convenient plotting)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KX-5Yw2w8KtY",
        "colab_type": "code",
        "outputId": "3a7cadcc-641f-4cbd-90f4-4afd41be6c2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "def plot_protein_length_distribution(aa_sequences: list):\n",
        "    import pandas as pd\n",
        "    pd.DataFrame({'gene length': map(lambda s: len(s), aa_sequences)}).hist(log=True)\n",
        "\n",
        "plot_protein_length_distribution(aa_sequences)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAASVklEQVR4nO3df6yf9V338edLkIntJHObZ1rQwzyI\nVjqdnAwXjfdp4qRY63QuSIMKBqkz1qjpnazc9x0lxt32NqIGRGeNCBrkiHMTCo2oiSfTiBOqU2AE\nxaVKK2ud1W5F4ix7+8e5yP1dd0777fdHv+f74flIGr7Xj891vd+96LtX39/Pua5UFZKktnzOpAOQ\nJI2exV2SGmRxl6QGWdwlqUEWd0lqkMVdkhpkcZdWkaSSzE3gvAtJDp3r86otFndpwib1l4jaZnGX\npAZZ3LXmJPm6JH+d5JNJfjfJ7yT56Z7t35bkw0n+PcmfJ3lTz7aDSf5nkr9Ncrwb+3n9jD1DTK9K\n8nNJ/inJkSTvTXJht20hyaEku5IcTfJ8ku/vGfvaJPuSfCLJY0l+Osmfdds+2O32N0lOJPnunnEr\nHk/qh8Vda0qSC4APAHcDXwjcB3xnz/Y3A3cBPwi8FvhV4MEkr+o5zLXAFuBS4E3AjWcxdjV7gK8A\nvhaYAzYAP9Gz/Q3ARd36m4A7k7ym23Yn8EK3zw3dLwCq6pu6j19TVeur6nf6OJ50RhZ3rTVfD5wP\n3F5V/1VV7wf+smf7DuBXq+pDVfVSVd0D/Gc37mW3V9U/V9UxYB/LBbnfsZ8lSbqxP15Vx6rqk8D/\nBa7r2e2/gJ/qYt4PnAAuT3Ie8F3AT1bVf1TVR4B7+vh9WPF4fYyTgOU/RNJa8iXA4frMJ9o91/P5\ny4AbkvxIz7oLunEv+1jP5//o2dbP2JW8Hvh84MBynQcgwHk9+/xrVZ085bzru7Hnn5JD7+fVrHY8\nqS8Wd601zwMbkqSnwF8C/EP3+TngPVX1ngGOPejYjwMvAl9dVYfPcuy/ACeBi4G/69ZdcpbHkM6a\nbRmtNY8CLwE7k5yf5O3AW3q2/xrwriRXZdm6JFuTvLqPYw80tqo+3Y39hSRfBJBkQ5Krz3TCqnoJ\neD9wa5LPT/KVwPedstsR4I19xC/1zeKuNaWqPgW8g+UvEf8d+B7gIZZ741TV48DNwC8B/wY8S/eF\naR/HHngs8O5u/79I8gngj+m/B76T5S9HPwb8FstfEv9nz/ZbgXu6GTzX9nlM6bTiyzq01iX5EPDe\nqvqNSccyCkn+H/CGqrrhjDtLA/LOXWtOkv+R5A1dW+YGlqcz/sGk4xpUkq9M8qauFfQWlv9V8oFJ\nx6W2+YWq1qLLgfuBdcBHgXdW1fOTDWkor2a5FfMlLPfXbwMemGhEap5tGUlqkG0ZSWrQmmjLvO51\nr6vZ2dmBxr7wwgusW7dutAGtMa3naH7Tr/Uc12p+Bw4c+HhVvX6lbWuiuM/OzvL4448PNHZpaYmF\nhYXRBrTGtJ6j+U2/1nNcq/kl+cfVtk20LZNkW5K9x48fn2QYktSciRb3qtpXVTsuuuiiSYYhSc3x\nC1VJapDFXZIaZHGXpAb5haokNcgvVCWpQbZlJKlBa+KHmIbxxOHj3Lj74Ymc++CerRM5rySdiXfu\nktQgi7skNcjiLkkNsrhLUoOc5y5JDXKeuyQ1yLaMJDXI4i5JDbK4S1KDLO6S1CCLuyQ1yOIuSQ2y\nuEtSgyzuktSgsRT3JOuSPJ7k28ZxfEnS6fVV3JPcleRokidPWb8lyTNJnk2yu2fTu4H7RxmoJKl/\n/d653w1s6V2R5DzgTuAaYCOwPcnGJG8DPgIcHWGckqSz0NebmKrqg0lmT1n9FuDZqvooQJJF4O3A\nemAdywX/xST7q+rTI4tYknRGqar+dlwu7g9V1RXd8juBLVX1A93y9wJXVdXObvlG4ONV9dAqx9sB\n7ACYmZm5cnFxcaAEjh47zpEXBxo6tE0bzs0Dz06cOMH69evPybkmwfymX+s5rtX8Nm/efKCq5lfa\nNrZ3qFbV3WfYvhfYCzA/P18LCwsDneeOex/gticm8yrYg9cvnJPzLC0tMejvzzQwv+nXeo7TmN8w\ns2UOA5f0LF/creubz3OXpPEYprg/BlyW5NIkFwDXAQ+ezQF8nrskjUe/UyHvAx4FLk9yKMlNVXUS\n2Ak8AjwN3F9VT53Nyb1zl6Tx6He2zPZV1u8H9g968qraB+ybn5+/edBjSJI+m48fkKQG+YJsSWqQ\nL8iWpAbZlpGkBtmWkaQG2ZaRpAbZlpGkBk3moSydJNuAbXNzc5MMY2Czux8+J+fZtekkN/ac6+Ce\nrefkvJKml20ZSWqQbRlJapDFXZIa5FRISWqQPXdJapBtGUlqkMVdkhpkcZekBlncJalBzpaRpAY5\nW0aSGmRbRpIaZHGXpAZZ3CWpQRZ3SWqQxV2SGmRxl6QGOc9dkhrkPHdJapBtGUlqkMVdkhpkcZek\nBlncJalBFndJapDFXZIaZHGXpAZZ3CWpQSMv7km+Ksl7k7wvyQ+N+viSpDPrq7gnuSvJ0SRPnrJ+\nS5JnkjybZDdAVT1dVe8CrgW+YfQhS5LOpN8797uBLb0rkpwH3AlcA2wEtifZ2G37duBhYP/IIpUk\n9S1V1d+OySzwUFVd0S2/Fbi1qq7ulm8BqKqf6RnzcFVtXeV4O4AdADMzM1cuLi4OlMDRY8c58uJA\nQ6fGzIV8Ro6bNrT1LJ4TJ06wfv36SYcxNq3nB+3nuFbz27x584Gqml9p2/lDHHcD8FzP8iHgqiQL\nwDuAV3GaO/eq2gvsBZifn6+FhYWBgrjj3ge47Ylh0lj7dm06+Rk5Hrx+YXLBjMHS0hKDXv9p0Hp+\n0H6O05jfyKtiVS0BS/3sm2QbsG1ubm7UYUjSK9ows2UOA5f0LF/creubj/yVpPEYprg/BlyW5NIk\nFwDXAQ+OJixJ0jD6nQp5H/AocHmSQ0luqqqTwE7gEeBp4P6qeupsTu6bmCRpPPrquVfV9lXW72eI\n6Y5VtQ/YNz8/f/Ogx3glmt398MTOfXDPipOfJK0xvkNVkhrkO1QlqUE+OEySGmRbRpIaZFtGkhpk\nW0aSGmRxl6QG2XOXpAbZc5ekBtmWkaQGWdwlqUH23CWpQfbcJalBtmUkqUEWd0lqkMVdkhpkcZek\nBjlbRpIa5GwZSWqQbRlJapDFXZIaZHGXpAZZ3CWpQRZ3SWqQxV2SGuQ8d0lqkPPcJalBtmUkqUEW\nd0lqkMVdkhpkcZekBlncJalBFndJatD5kw5A02V298MjP+auTSe58QzHPbhn68jPK7XMO3dJatBY\n7tyTfAewFfgC4Ner6g/HcR5J0sr6vnNPcleSo0mePGX9liTPJHk2yW6Aqvr9qroZeBfw3aMNWZJ0\nJmfTlrkb2NK7Isl5wJ3ANcBGYHuSjT27/J9uuyTpHEpV9b9zMgs8VFVXdMtvBW6tqqu75Vu6Xfd0\nv/6oqv54lWPtAHYAzMzMXLm4uDhQAkePHefIiwMNnRozF9J0jv3kt2nD9D5/6MSJE6xfv37SYYxV\n6zmu1fw2b958oKrmV9o2bM99A/Bcz/Ih4CrgR4BvBi5KMldV7z11YFXtBfYCzM/P18LCwkAB3HHv\nA9z2RNuTfnZtOtl0jv3kd/D6hXMTzBgsLS0x6P/f06L1HKcxv7FUjKq6Hbj9TPsl2QZsm5ubG0cY\nkvSKNexUyMPAJT3LF3fr+uIjfyVpPIYt7o8BlyW5NMkFwHXAg8OHJUkaxtlMhbwPeBS4PMmhJDdV\n1UlgJ/AI8DRwf1U9dRbH9E1MkjQGfffcq2r7Kuv3A/sHOXlV7QP2zc/P3zzIeEnSynyHqiQ1yHeo\nSlKDfHCYJDVooj8Z4zx39Wscjxruh48a1rSyLSNJDbItI0kNsrhLUoOcCilJDbLnLkkNsi0jSQ2y\nuEtSg+y5S1KD7LlLUoNsy0hSgyzuktQgi7skNcjiLkkNcraMJDXI2TKS1CDbMpLUIIu7JDXI4i5J\nDbK4S1KDLO6S1CCLuyQ1yHnuktQg57lLUoNsy0hSgyzuktQgi7skNcjiLkkNsrhLUoMs7pLUIIu7\nJDXI4i5JDTp/1AdM8kbgfwMXVdU7R3186Vya3f3w0MfYtekkNw5wnIN7tg59br1y9XXnnuSuJEeT\nPHnK+i1JnknybJLdAFX10aq6aRzBSpL6029b5m5gS++KJOcBdwLXABuB7Uk2jjQ6SdJAUlX97ZjM\nAg9V1RXd8luBW6vq6m75FoCq+plu+X2na8sk2QHsAJiZmblycXFxoASOHjvOkRcHGjo1Zi6k6RzN\nb2WbNkzPM5dOnDjB+vXrJx3G2KzV/DZv3nygquZX2jZMz30D8FzP8iHgqiSvBd4DvDnJLS8X+1NV\n1V5gL8D8/HwtLCwMFMQd9z7AbU+M/KuDNWXXppNN52h+Kzt4/cLogxmTpaUlBv0zPA2mMb+R/4mq\nqn8F3tXPvkm2Advm5uZGHYYkvaINMxXyMHBJz/LF3bq++chfSRqPYYr7Y8BlSS5NcgFwHfDg2RzA\nl3VI0nj0OxXyPuBR4PIkh5LcVFUngZ3AI8DTwP1V9dTZnNw7d0kaj7567lW1fZX1+4H9I41IkjQ0\n36EqSQ3yHaqS1CAfHCZJDbItI0kNsi0jSQ2yLSNJDbK4S1KD7LlLUoPsuUtSg2zLSFKDLO6S1CB7\n7pLUIHvuktQg2zKS1CCLuyQ1yOIuSQ2yuEtSg/p6E9O4JNkGbJubm5tkGNKaNLv74UmH0Lddm05y\n4wjiPbhn6wiiEThbRpKaZFtGkhpkcZekBlncJalBFndJapDFXZIa5FRISWvGpKZ/tjgF06mQktQg\n2zKS1CCLuyQ1yOIuSQ2yuEtSgyzuktQgi7skNcjiLkkNsrhLUoMs7pLUoJE/fiDJOuCXgU8BS1V1\n76jPIUk6vb7u3JPcleRokidPWb8lyTNJnk2yu1v9DuB9VXUz8O0jjleS1Id+2zJ3A1t6VyQ5D7gT\nuAbYCGxPshG4GHiu2+2l0YQpSTobqar+dkxmgYeq6opu+a3ArVV1dbd8S7frIeDfquqhJItVdd0q\nx9sB7ACYmZm5cnFxcaAEjh47zpEXBxo6NWYupOkczW/6tZ7jOPPbtGHwBydu3rz5QFXNr7RtmJ77\nBv7/HTosF/WrgNuBX0qyFdi32uCq2gvsBZifn6+FhYWBgrjj3ge47YmJPrl47HZtOtl0juY3/VrP\ncZz5Hbx+YSzHHXm0VfUC8P397Ovz3CVpPIaZCnkYuKRn+eJuXd98nrskjccwxf0x4LIklya5ALgO\nePBsDpBkW5K9x48fHyIMSdKp+p0KeR/wKHB5kkNJbqqqk8BO4BHgaeD+qnrqbE7unbskjUdfPfeq\n2r7K+v3A/pFGJEka2kQfP2BbRpLGwxdkS1KDfHCYJDWo759QHWsQyb8A/zjg8NcBHx9hOGtR6zma\n3/RrPce1mt+XVdXrV9qwJor7MJI8vtqP37ai9RzNb/q1nuM05mdbRpIaZHGXpAa1UNz3TjqAc6D1\nHM1v+rWe49TlN/U9d0nSZ2vhzl2SdAqLuyQ1aKqL+yrvcG1GkoNJnkjy4SSPTzqeUVjpfbxJvjDJ\nHyX5++6/r5lkjMNYJb9bkxzuruOHk3zrJGMcRpJLkvxJko8keSrJj3brm7iGp8lv6q7h1Pbcu3e4\n/h3wNpbfAvUYsL2qPjLRwEYoyUFgvqrW4g9PDCTJNwEngN/seWXjzwLHqmpP95f0a6rq3ZOMc1Cr\n5HcrcKKqfm6SsY1Cki8Gvriq/irJq4EDwHcAN9LANTxNftcyZddwmu/c3wI8W1UfrapPAYvA2ycc\nk86gqj4IHDtl9duBe7rP97D8h2kqrZJfM6rq+ar6q+7zJ1l+3PcGGrmGp8lv6kxzcV/pHa5TeRFO\no4A/THKge6F4q2aq6vnu88eAmUkGMyY7k/xt17aZypbFqZLMAm8GPkSD1/CU/GDKruE0F/dXgm+s\nqq8DrgF+uPsnf9NquU84nb3C1f0K8OXA1wLPA7dNNpzhJVkP/B7wY1X1id5tLVzDFfKbums4zcV9\n6He4rnVVdbj771HgAyy3olp0pOt1vtzzPDrheEaqqo5U1UtV9Wng15jy65jkc1kufPdW1fu71c1c\nw5Xym8ZrOM3Ffeh3uK5lSdZ1X+iQZB3wLcCTpx81tR4Ebug+3wA8MMFYRu7lotf5Tqb4OiYJ8OvA\n01X18z2bmriGq+U3jddwamfLAHTTkX4ROA+4q6reM+GQRibJG1m+W4fl1yH+dgv5de/jXWD5EapH\ngJ8Efh+4H/hSlh/9fG1VTeWXkqvkt8DyP+cLOAj8YE9/eqok+UbgT4EngE93q/8Xy33pqb+Gp8lv\nO1N2Dae6uEuSVjbNbRlJ0ios7pLUIIu7JDXI4i5JDbK4S1KDLO6S1CCLuyQ16L8BgmrTEgrTEAcA\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxT7xooTspld",
        "colab_type": "text"
      },
      "source": [
        "### Compare with baseline\n",
        "\n",
        "Load the protein FASTA exported by Augusts (in **Task 1**) and plot the protein length distribution.\n",
        "\n",
        "You can use the function below to read the fasta once you upload it to Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9Wxw47yszLR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_protein_sequences_from_fasta(fasta_filename: str) -> list:\n",
        "     return list(SeqIO.parse(fasta_filename, 'fasta'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D6k3Ao8syoO",
        "colab_type": "text"
      },
      "source": [
        "#### Optional: Save to FASTA and blastp\n",
        "\n",
        "We can save the protein sequences to a FASTA file, download it, upload it to the server and blast it against the Augustus FASTA file.\n",
        "For blasting, see the last part here: https://mpbio-bbt015.github.io/gene-prediction-exercise.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJqrsSW3E28Q",
        "colab_type": "code",
        "outputId": "267bf5d7-e752-4dc0-eecc-a0131a433f5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def save_sequences_as_fasta(sequences: list, fasta_filename: str):\n",
        "    fasta_entries = []\n",
        "    for i in range(len(sequences)):\n",
        "        if len(sequences[i]) > 20:   # shortest known protein in any organism\n",
        "            fasta_entries.append(f'>gene{i}\\n{sequences[i]}\\n')\n",
        "    with open(fasta_filename, 'w') as output_fasta:\n",
        "        output_fasta.writelines(fasta_entries)\n",
        "    print(f'INFO: Wrote {len(fasta_entries)} protein sequences')\n",
        "\n",
        "save_sequences_as_fasta(aa_sequences, 'hits.fasta')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO: Wrote 4 protein sequences\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLWQfnByvYBx",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fICvPlh8th9l",
        "colab_type": "text"
      },
      "source": [
        "## Assignment: Build a better HMM\n",
        "\n",
        "Your turn! Create a better HMM using the example and code provided and try your best to get better results. \n",
        "\n",
        "How well can you do against Augustus? :)  (the important thing is to build + use the model so don't worry about matching it - just aim to improve results)\n",
        "\n",
        "Remember:\n",
        "\n",
        "* very briefly describe your model\n",
        "* try to train on all chromosomes (adjust the code)\n",
        "* try to tweak training paramenters (like max n. iterations) to get a better fit to training data\n",
        "* try different random seeds\n",
        "* perhaps try different training algorithms? hmmlearn provides an alternative to Viterbi.\n",
        "* You can **save trained models to a file**! Very usedul if you've spend a lot of time training. (Colab clears everything when it disconnects). See here https://hmmlearn.readthedocs.io/en/latest/tutorial.html#saving-and-loading-hmm\n",
        "\n",
        "\n",
        "**Have fun!**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0af1R91n4hzd",
        "colab_type": "text"
      },
      "source": [
        "![xkcd](https://imgs.xkcd.com/comics/machine_learning.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiM6FTjmi-S9",
        "colab_type": "text"
      },
      "source": [
        "#########TRYING TO IMPROVE THE MODEL##############\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIvO5q684ooT",
        "colab_type": "code",
        "outputId": "faf0a2af-ef8c-4818-dd06-d0cbba23a6b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        " #Trying to build a better HMM model\n",
        " hidden_states = ['I', 'E', 'Ig']               # Called \"components\" in this package\n",
        "emission_labels = ['A', 'T', 'C', 'G']   # Called \"fatures\"\n",
        "\n",
        "# Maximum n. iterations performed during training.\n",
        "# The training will stop at this regardless of how close it is to convergence (i.e. best fit to data)\n",
        "# Increasing will increase chances of a better fit but will of course take longer\n",
        "MAX_N_BAUM_WELCH_ITERATIONS = 80\n",
        "\n",
        "# Create model object\n",
        "basic_model = hmm.MultinomialHMM(n_components = len(hidden_states),\n",
        "                                 n_iter = MAX_N_BAUM_WELCH_ITERATIONS,\n",
        "                                 init_params = \"\")\n",
        "\n",
        "# Adjust its parameters\n",
        "basic_model.n_features = len(emission_labels)\n",
        "\n",
        "# Order of elements must match those in the component and features lists above\n",
        "basic_model.startprob_ = np.array([0.2, 0.3, 0.5])\n",
        "basic_model.transmat_ = np.array([[0.99, 0.01, 0],\n",
        "                                  [0.007,  0.99, 0.003],\n",
        "                                  [0, 0.001, 0.999]])\n",
        "\n",
        "# The matrix is expected to be of shape (rows=states x cols=emissions)\n",
        "# Here it's transposed from the form used in lecture slides\n",
        "basic_model.emissionprob_ = np.array([[0.26, 0.24, 0.27],\n",
        "                                      [0.3, 0.21, 0.27],\n",
        "                                      [0.22, 0.27, 0.23],\n",
        "                                      [0.22, 0.28, 0.22]]).T\n",
        "\n",
        "# Preview\n",
        "basic_model"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialHMM(algorithm='viterbi', init_params='', n_components=3, n_iter=80,\n",
              "               params='ste', random_state=None, startprob_prior=1.0, tol=0.01,\n",
              "               transmat_prior=1.0, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omLHiucQjFts",
        "colab_type": "text"
      },
      "source": [
        "I chose the emission probabilities from the lecture from the University of Waterloo. The starting probabilities aim to reflect that it is more likely to start in a non coding region since non-coding regions are very abundant in eukaryotic genomes. The probability should be a big higher than 0.5, but I wanted to use this as a starting point. I also tried to add a bit more of complexity by using introns and exons, and I gave them a similar probability, although slightly higher for exons because I think it is more likely that a gene starts with an exon than an intron. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQo6a19FExkz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1od7eifsExUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Preparation of training data\n",
        "# Include k chromosomes in training data\n",
        "training_chromosome_idx = [0, 1, 2, 3]\n",
        "\n",
        "trainig_data = np.concatenate(\n",
        "    [np.array(\n",
        "        translate_symbol_sequence_to_numbers(ref_chromosomes[k].seq, emission_labels)\n",
        "        ).reshape(-1, 1)  # makes it a column vector\n",
        "     for k in training_chromosome_idx]\n",
        ")\n",
        "\n",
        "trainig_lengths = [len(ref_chromosomes[k].seq) for k in training_chromosome_idx]\n",
        "\n",
        "# Test on chromosome 1\n",
        "test_data = np.array(\n",
        "    [translate_symbol_sequence_to_numbers(ref_chromosomes[0].seq, emission_labels)]\n",
        ").T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yldMO2UpE1pL",
        "colab_type": "code",
        "outputId": "524fd2e7-6d2d-45dc-e5ad-2e7dd98718c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Training\n",
        "t0 = time.time()    # this is just to measure execution time (nothing to do with hmmlearn)\n",
        "np.random.seed(84)  # Make this randomized procedure deterministic (reproducible)\n",
        "\n",
        "basic_model.fit(trainig_data, trainig_lengths)\n",
        "\n",
        "print(f'Training took {time.time() - t0} seconds')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training took 1434.3676676750183 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRPuR_o7E_GR",
        "colab_type": "code",
        "outputId": "072d9efd-d2c3-4762-f5c0-6dcdf4d88d40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#Annotation\n",
        "annotation_numeric = basic_model.predict(test_data)  # numbers == hidden state number\n",
        "annotation = translate_numbers_to_symbol_sequence(annotation_numeric, hidden_states)\n",
        "\n",
        "# Preview first 100 annotated bases\n",
        "annotation[0:1000]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIEEEIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgIgI'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reHtQ_fxWlGE",
        "colab_type": "code",
        "outputId": "597aa6bd-40e3-47c6-c980-18e04c93fa0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "gene_positions = get_gene_start_and_stop_from_annotation(annotation, \n",
        "                                                         gene_pattern = 'E+I+')\n",
        "\n",
        "# Preview gene positions\n",
        "gene_positions[0:4]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 636), (636, 640), (25085, 25359), (47106, 47525)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_ZxTMjtWqIW",
        "colab_type": "code",
        "outputId": "71d12601-c0e4-432d-9a59-0871d88c6273",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "def translate_genes(gene_positions: list, dna_sequence) -> list:\n",
        "    aa_sequences = []\n",
        "    for gene_pos in gene_positions:\n",
        "        aa = dna_sequence[gene_pos[0] : gene_pos[1]].transcribe().translate()\n",
        "        aa_sequences.append(aa)\n",
        "    return aa_sequences\n",
        "\n",
        "aa_sequences = translate_genes(gene_positions, ref_chromosomes[0].seq)\n",
        "\n",
        "# Preview\n",
        "aa_sequences[0]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/Bio/Seq.py:2859: BiopythonWarning: Partial codon, len(sequence) not a multiple of three. Explicitly trim the sequence or add trailing N before translation. This may become an error in future.\n",
            "  BiopythonWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq('PHHTHTPTHHTTHHTTPTHTHPNTTLTQP*SNPGQPVSQLTLHYPASTRYPVPF...GGP', HasStopCodon(ExtendedIUPACProtein(), '*'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxjIq0DGWrbr",
        "colab_type": "code",
        "outputId": "10f43492-cab1-4d20-db86-33ef14b71712",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "def plot_protein_length_distribution(aa_sequences: list):\n",
        "    import pandas as pd\n",
        "    pd.DataFrame({'gene length': map(lambda s: len(s), aa_sequences)}).hist(log=True)\n",
        "\n",
        "plot_protein_length_distribution(aa_sequences)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGWH4JcYwVuK",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "With 3 chromosomes, 84 random seeds and 50 iterations the results look quite similar than with 42 iterations and/or 2 chromosomes, but the gene legth distribution does change. We get a range from 0-1000 which seems a bit more realistic than what we had before (0-25), although still considerably shorter than what is expected for a S. cerevisiae gene, which is on average 1.6 kb long (https://bionumbers.hms.harvard.edu/bionumber.aspx?id=101458&ver=1). Also, most sequences are below 200 so the distribution is still skewed towards very short fragments. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWf3UT_-9x7E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "outputId": "95045c23-d860-4d37-c386-c816b85c882b"
      },
      "source": [
        " #Trying to build a better HMM model\n",
        " hidden_states = ['I', 'E', 'Ig']               # Called \"components\" in this package\n",
        "emission_labels = ['A', 'T', 'C', 'G']   # Called \"fatures\"\n",
        "\n",
        "# Maximum n. iterations performed during training.\n",
        "# The training will stop at this regardless of how close it is to convergence (i.e. best fit to data)\n",
        "# Increasing will increase chances of a better fit but will of course take longer\n",
        "MAX_N_BAUM_WELCH_ITERATIONS = 80\n",
        "\n",
        "# Create model object\n",
        "basic_model = hmm.MultinomialHMM(n_components = len(hidden_states),\n",
        "                                 n_iter = MAX_N_BAUM_WELCH_ITERATIONS,\n",
        "                                 init_params = \"\")\n",
        "\n",
        "# Adjust its parameters\n",
        "basic_model.n_features = len(emission_labels)\n",
        "\n",
        "# Order of elements must match those in the component and features lists above\n",
        "basic_model.startprob_ = np.array([0.2, 0.3, 0.5])\n",
        "basic_model.transmat_ = np.array([[0.99, 0.01, 0],\n",
        "                                  [0.007,  0.99, 0.003],\n",
        "                                  [0, 0.001, 0.999]])\n",
        "\n",
        "# The matrix is expected to be of shape (rows=states x cols=emissions)\n",
        "# Here it's transposed from the form used in lecture slides\n",
        "basic_model.emissionprob_ = np.array([[0.26, 0.24, 0.27],\n",
        "                                      [0.3, 0.21, 0.27],\n",
        "                                      [0.22, 0.27, 0.23],\n",
        "                                      [0.22, 0.28, 0.22]]).T\n",
        "\n",
        "# Preview\n",
        "basic_model\n",
        "#Preparation of training data\n",
        "# Include k chromosomes in training data\n",
        "training_chromosome_idx = [0, 1, 2, 3, 4, 5]\n",
        "\n",
        "trainig_data = np.concatenate(\n",
        "    [np.array(\n",
        "        translate_symbol_sequence_to_numbers(ref_chromosomes[k].seq, emission_labels)\n",
        "        ).reshape(-1, 1)  # makes it a column vector\n",
        "     for k in training_chromosome_idx]\n",
        ")\n",
        "\n",
        "trainig_lengths = [len(ref_chromosomes[k].seq) for k in training_chromosome_idx]\n",
        "\n",
        "# Test on chromosome 1\n",
        "test_data = np.array(\n",
        "    [translate_symbol_sequence_to_numbers(ref_chromosomes[0].seq, emission_labels)]\n",
        ").T\n",
        "#Training\n",
        "t0 = time.time()    # this is just to measure execution time (nothing to do with hmmlearn)\n",
        "np.random.seed(84)  # Make this randomized procedure deterministic (reproducible)\n",
        "\n",
        "basic_model.fit(trainig_data, trainig_lengths)\n",
        "\n",
        "print(f'Training took {time.time() - t0} seconds')\n",
        "#Annotation\n",
        "annotation_numeric = basic_model.predict(test_data)  # numbers == hidden state number\n",
        "annotation = translate_numbers_to_symbol_sequence(annotation_numeric, hidden_states)\n",
        "\n",
        "# Preview first 100 annotated bases\n",
        "annotation[0:1000]\n",
        "\n",
        "gene_positions = get_gene_start_and_stop_from_annotation(annotation, \n",
        "                                                         gene_pattern = 'E+I+')\n",
        "\n",
        "# Preview gene positions\n",
        "gene_positions[0:4]\n",
        "\n",
        "def translate_genes(gene_positions: list, dna_sequence) -> list:\n",
        "    aa_sequences = []\n",
        "    for gene_pos in gene_positions:\n",
        "        aa = dna_sequence[gene_pos[0] : gene_pos[1]].transcribe().translate()\n",
        "        aa_sequences.append(aa)\n",
        "    return aa_sequences\n",
        "\n",
        "aa_sequences = translate_genes(gene_positions, ref_chromosomes[0].seq)\n",
        "\n",
        "# Preview\n",
        "aa_sequences[0]\n",
        "\n",
        "def plot_protein_length_distribution(aa_sequences: list):\n",
        "    import pandas as pd\n",
        "    pd.DataFrame({'gene length': map(lambda s: len(s), aa_sequences)}).hist(log=True)\n",
        "\n",
        "plot_protein_length_distribution(aa_sequences)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training took 1864.0024154186249 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/Bio/Seq.py:2859: BiopythonWarning: Partial codon, len(sequence) not a multiple of three. Explicitly trim the sequence or add trailing N before translation. This may become an error in future.\n",
            "  BiopythonWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xO-DDX4RPOG",
        "colab_type": "text"
      },
      "source": [
        "Here I tried to retrain the model including a larger number of chromosomes but it did not seem to improve. It may be that including an even larger number of chromosomes would be helpful, but due to lack of time I did not. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YW9CGaidRfMY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "outputId": "5ca33a63-ab4c-4693-ac8d-903db469d7e0"
      },
      "source": [
        " #Trying to build a better HMM model\n",
        " hidden_states = ['I', 'E', 'Ig']               # Called \"components\" in this package\n",
        "emission_labels = ['A', 'T', 'C', 'G']   # Called \"fatures\"\n",
        "\n",
        "# Maximum n. iterations performed during training.\n",
        "# The training will stop at this regardless of how close it is to convergence (i.e. best fit to data)\n",
        "# Increasing will increase chances of a better fit but will of course take longer\n",
        "MAX_N_BAUM_WELCH_ITERATIONS = 100\n",
        "\n",
        "# Create model object\n",
        "basic_model = hmm.MultinomialHMM(n_components = len(hidden_states),\n",
        "                                 n_iter = MAX_N_BAUM_WELCH_ITERATIONS,\n",
        "                                 init_params = \"\")\n",
        "\n",
        "# Adjust its parameters\n",
        "basic_model.n_features = len(emission_labels)\n",
        "\n",
        "# Order of elements must match those in the component and features lists above\n",
        "basic_model.startprob_ = np.array([0.2, 0.3, 0.5])\n",
        "basic_model.transmat_ = np.array([[0.99, 0.01, 0],\n",
        "                                  [0.007,  0.99, 0.003],\n",
        "                                  [0, 0.001, 0.999]])\n",
        "\n",
        "# The matrix is expected to be of shape (rows=states x cols=emissions)\n",
        "# Here it's transposed from the form used in lecture slides\n",
        "basic_model.emissionprob_ = np.array([[0.26, 0.24, 0.27],\n",
        "                                      [0.3, 0.21, 0.27],\n",
        "                                      [0.22, 0.27, 0.23],\n",
        "                                      [0.22, 0.28, 0.22]]).T\n",
        "\n",
        "# Preview\n",
        "basic_model\n",
        "#Preparation of training data\n",
        "# Include k chromosomes in training data\n",
        "training_chromosome_idx = [0, 1, 2, 3, 4, 5]\n",
        "\n",
        "trainig_data = np.concatenate(\n",
        "    [np.array(\n",
        "        translate_symbol_sequence_to_numbers(ref_chromosomes[k].seq, emission_labels)\n",
        "        ).reshape(-1, 1)  # makes it a column vector\n",
        "     for k in training_chromosome_idx]\n",
        ")\n",
        "\n",
        "trainig_lengths = [len(ref_chromosomes[k].seq) for k in training_chromosome_idx]\n",
        "\n",
        "# Test on chromosome 1\n",
        "test_data = np.array(\n",
        "    [translate_symbol_sequence_to_numbers(ref_chromosomes[0].seq, emission_labels)]\n",
        ").T\n",
        "#Training\n",
        "t0 = time.time()    # this is just to measure execution time (nothing to do with hmmlearn)\n",
        "np.random.seed(84)  # Make this randomized procedure deterministic (reproducible)\n",
        "\n",
        "basic_model.fit(trainig_data, trainig_lengths)\n",
        "\n",
        "print(f'Training took {time.time() - t0} seconds')\n",
        "#Annotation\n",
        "annotation_numeric = basic_model.predict(test_data)  # numbers == hidden state number\n",
        "annotation = translate_numbers_to_symbol_sequence(annotation_numeric, hidden_states)\n",
        "\n",
        "# Preview first 100 annotated bases\n",
        "annotation[0:1000]\n",
        "\n",
        "gene_positions = get_gene_start_and_stop_from_annotation(annotation, \n",
        "                                                         gene_pattern = 'E+I+')\n",
        "\n",
        "# Preview gene positions\n",
        "gene_positions[0:4]\n",
        "\n",
        "def translate_genes(gene_positions: list, dna_sequence) -> list:\n",
        "    aa_sequences = []\n",
        "    for gene_pos in gene_positions:\n",
        "        aa = dna_sequence[gene_pos[0] : gene_pos[1]].transcribe().translate()\n",
        "        aa_sequences.append(aa)\n",
        "    return aa_sequences\n",
        "\n",
        "aa_sequences = translate_genes(gene_positions, ref_chromosomes[0].seq)\n",
        "\n",
        "# Preview\n",
        "aa_sequences[0]\n",
        "\n",
        "def plot_protein_length_distribution(aa_sequences: list):\n",
        "    import pandas as pd\n",
        "    pd.DataFrame({'gene length': map(lambda s: len(s), aa_sequences)}).hist(log=True)\n",
        "\n",
        "plot_protein_length_distribution(aa_sequences)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training took 2316.914821624756 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/Bio/Seq.py:2859: BiopythonWarning: Partial codon, len(sequence) not a multiple of three. Explicitly trim the sequence or add trailing N before translation. This may become an error in future.\n",
            "  BiopythonWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJs2/3WlgpdcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MJy2x-PWFHm",
        "colab_type": "text"
      },
      "source": [
        "I increased the number of iterations once more to see if it would make a difference even though by training on the number of chromosomes seemed to lead to a plateau. It seemed to average most genes to a shorter length than the previous model and has more genes above 200 bp but the longest gene is shorter than before (500 bp compared to 800 bp) so we do not get closer to the expected length. However, this is not very surprising because of the way that the model is looking for gene patterns, considering a gene as a string of \"exon\" and \"intron\", whereas a real gene can consist of several exons and introns. Therefore we are obviously splitting most genes and it is hard to get genes of the expected size that consist of only one gene and intron. However, since this model does have a more equal distribution and more \"longer\" genes, I would say the larger number of iterations still improved the model.\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd-X04qEcCcF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "outputId": "26f79b9f-1c76-47f2-ea17-430fac65a3fd"
      },
      "source": [
        " #Trying to build a better HMM model\n",
        " hidden_states = ['I', 'E', 'Ig']               # Called \"components\" in this package\n",
        "emission_labels = ['A', 'T', 'C', 'G']   # Called \"fatures\"\n",
        "\n",
        "# Maximum n. iterations performed during training.\n",
        "# The training will stop at this regardless of how close it is to convergence (i.e. best fit to data)\n",
        "# Increasing will increase chances of a better fit but will of course take longer\n",
        "MAX_N_BAUM_WELCH_ITERATIONS = 100\n",
        "\n",
        "# Create model object\n",
        "basic_model = hmm.MultinomialHMM(n_components = len(hidden_states),\n",
        "                                 n_iter = MAX_N_BAUM_WELCH_ITERATIONS,\n",
        "                                 init_params = \"\")\n",
        "\n",
        "# Adjust its parameters\n",
        "basic_model.n_features = len(emission_labels)\n",
        "\n",
        "# Order of elements must match those in the component and features lists above\n",
        "basic_model.startprob_ = np.array([0.2, 0.3, 0.5])\n",
        "basic_model.transmat_ = np.array([[0.99, 0.01, 0],\n",
        "                                  [0.007,  0.99, 0.003],\n",
        "                                  [0, 0.001, 0.999]])\n",
        "\n",
        "# The matrix is expected to be of shape (rows=states x cols=emissions)\n",
        "# Here it's transposed from the form used in lecture slides\n",
        "basic_model.emissionprob_ = np.array([[0.26, 0.24, 0.27],\n",
        "                                      [0.3, 0.21, 0.27],\n",
        "                                      [0.22, 0.27, 0.23],\n",
        "                                      [0.22, 0.28, 0.22]]).T\n",
        "\n",
        "# Preview\n",
        "basic_model\n",
        "#Preparation of training data\n",
        "# Include k chromosomes in training data\n",
        "training_chromosome_idx = [0, 1, 2, 3, 4, 5]\n",
        "\n",
        "trainig_data = np.concatenate(\n",
        "    [np.array(\n",
        "        translate_symbol_sequence_to_numbers(ref_chromosomes[k].seq, emission_labels)\n",
        "        ).reshape(-1, 1)  # makes it a column vector\n",
        "     for k in training_chromosome_idx]\n",
        ")\n",
        "\n",
        "trainig_lengths = [len(ref_chromosomes[k].seq) for k in training_chromosome_idx]\n",
        "\n",
        "# Test on chromosome 1\n",
        "test_data = np.array(\n",
        "    [translate_symbol_sequence_to_numbers(ref_chromosomes[0].seq, emission_labels)]\n",
        ").T\n",
        "#Training\n",
        "t0 = time.time()    # this is just to measure execution time (nothing to do with hmmlearn)\n",
        "np.random.seed(84)  # Make this randomized procedure deterministic (reproducible)\n",
        "\n",
        "basic_model.fit(trainig_data, trainig_lengths)\n",
        "\n",
        "print(f'Training took {time.time() - t0} seconds')\n",
        "#Annotation\n",
        "annotation_numeric = basic_model.predict(test_data)  # numbers == hidden state number\n",
        "annotation = translate_numbers_to_symbol_sequence(annotation_numeric, hidden_states)\n",
        "\n",
        "# Preview first 100 annotated bases\n",
        "annotation[0:1000]\n",
        "\n",
        "gene_positions = get_gene_start_and_stop_from_annotation(annotation, \n",
        "                                                         gene_pattern = 'E+I+E+')\n",
        "\n",
        "# Preview gene positions\n",
        "gene_positions[0:4]\n",
        "\n",
        "def translate_genes(gene_positions: list, dna_sequence) -> list:\n",
        "    aa_sequences = []\n",
        "    for gene_pos in gene_positions:\n",
        "        aa = dna_sequence[gene_pos[0] : gene_pos[1]].transcribe().translate()\n",
        "        aa_sequences.append(aa)\n",
        "    return aa_sequences\n",
        "\n",
        "aa_sequences = translate_genes(gene_positions, ref_chromosomes[0].seq)\n",
        "\n",
        "# Preview\n",
        "aa_sequences[0]\n",
        "\n",
        "def plot_protein_length_distribution(aa_sequences: list):\n",
        "    import pandas as pd\n",
        "    pd.DataFrame({'gene length': map(lambda s: len(s), aa_sequences)}).hist(log=True)\n",
        "\n",
        "plot_protein_length_distribution(aa_sequences)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training took 2306.622861623764 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/Bio/Seq.py:2859: BiopythonWarning: Partial codon, len(sequence) not a multiple of three. Explicitly trim the sequence or add trailing N before translation. This may become an error in future.\n",
            "  BiopythonWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAO4ElEQVR4nO3df6zddX3H8edrdKAWUxWwaiEWUoZh\ngqiNQma2i8kminWZIw7iIpjGzmQsbmHZIEscW3TDZM4NZdMuOsxCqD+mASqZ81ezLHMonSggQ9HU\nAUMqIldBoxbf++N8y461hdN7Lz33vs/zkZz0+/18f33et6evfu/nfM/3m6pCktTLz027A5KkpWe4\nS1JDhrskNWS4S1JDhrskNWS4S1JDhrt0AEkqyYYpHHcuyV2H+rjqxXCXpmxa/4moN8Ndkhoy3LXs\nJHlBki8k+V6SDyX5QJK3jC1/ZZKbkjyQ5D+SnDq2bFeSP0zypSTzw7ZPmGTbx+jTEUn+Ksn/JLk3\nybuTPHFYNpfkriQXJdmd5J4krx/b9qgk1yX5bpLPJ3lLkn8flv3bsNoXkzyY5LfGttvv/qRJGO5a\nVpIcDnwUuBJ4GnA18Btjy58PvA/4HeAo4D3AtUmOGNvNa4CzgOOBU4ELDmLbA7kM+AXgNGADsA54\n89jyZwBrhvbNwBVJnjosuwJ4aFjn/OEFQFX98jD5vKo6sqo+MMH+pMdkuGu5OR1YBVxeVT+uqo8A\nnxtbvgV4T1XdUFUPV9X7gR8O2+11eVX9b1XdD1zHKJAn3fZnJMmw7R9U1f1V9T3gL4Bzx1b7MfDn\nQ5+vBx4ETkpyGPCbwJ9W1fer6svA+yf4Oex3fxNsJwGjf0TScvIs4O766Tva3Tk2/Wzg/CS/N9Z2\n+LDdXt8cm/7+2LJJtt2fY4AnATtHOQ9AgMPG1vl2Ve3Z57hHDtuu2qeG8ekDOdD+pIkY7lpu7gHW\nJclYwB8HfG2YvhN4a1W9dQH7Xui29wE/AH6xqu4+yG2/BewBjgW+MrQdd5D7kA6awzJabj4LPAxc\nmGRVkl8HXjS2/B+ANyZ5cUZWJzk7yZMn2PeCtq2qnwzbviPJ0wGSrEvyssc6YFU9DHwEuDTJk5I8\nB3jdPqvdC5wwQf+liRnuWlaq6kfAqxl9iPgA8NvAdkZj41TVjcAbgHcB3wHuYPjAdIJ9L3hb4I+H\n9f8zyXeBTzL5GPiFjD4c/SbwT4w+JP7h2PJLgfcPV/C8ZsJ9So8qPqxDy12SG4B3V9U/TrsvSyHJ\n24BnVNX5j7mytECeuWvZSfIrSZ4xDMucz+hyxn+Zdr8WKslzkpw6DAW9iNFvJR+ddr/Umx+oajk6\nCfggsBr4OnBOVd0z3S4typMZDcU8i9H4+tuBa6baI7XnsIwkNeSwjCQ1tCyGZY4++uhav379grZ9\n6KGHWL169dJ2aBmahTpnoUaYjTpnoUaYfp07d+68r6qO2d+yZRHu69ev58Ybb1zQtjt27GBubm5p\nO7QMzUKds1AjzEads1AjTL/OJN840DKHZSSpIcNdkhoy3CWpIcNdkhoy3CWpIcNdkhoy3CWpIcNd\nkhpaFl9iWoyb757ngos/NpVj77rs7KkcV5Iei2fuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnu\nktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ\n4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5JDRnuktSQ4S5J\nDRnuktTQkod7khOSvDfJh5d635KkyUwU7knel2R3klv2aT8rye1J7khyMUBVfb2qNj8enZUkTWbS\nM/crgbPGG5IcBlwBvBw4GTgvyclL2jtJ0oKkqiZbMVkPbK+q5w7zZwCXVtXLhvlLAKrqL4f5D1fV\nOY+yvy3AFoC1a9e+cNu2bQsqYPf989z7gwVtuminrFtzyI714IMPcuSRRx6y403DLNQIs1HnLNQI\n06/zzDPP3FlVG/e3bNUi9rsOuHNs/i7gxUmOAt4KPD/JJXvDfl9VtRXYCrBx48aam5tbUCfeedU1\nvP3mxZSxcLteO3fIjrVjxw4W+jNaKWahRpiNOmehRljedS55KlbVt4E3LvV+JUmTW8zVMncDx43N\nHzu0SZKmbDHh/nngxCTHJzkcOBe4dmm6JUlajEkvhbwa+CxwUpK7kmyuqj3AhcDHgduAD1bVrY9f\nVyVJk5pozL2qzjtA+/XA9UvaI0nSonn7AUlqaKrhnmRTkq3z8/PT7IYktTPVcK+q66pqy5o1h+7L\nQJI0CxyWkaSGDHdJashwl6SGDHdJashwl6SGDHdJasjr3CWpIa9zl6SGHJaRpIYMd0lqyHCXpIYM\nd0lqyHCXpIYMd0lqyHCXpIb8EpMkNeSXmCSpIYdlJKkhw12SGjLcJakhw12SGjLcJakhw12SGjLc\nJakhw12SGjLcJakhbz8gSQ15+wFJashhGUlqyHCXpIYMd0lqyHCXpIYMd0lqyHCXpIYMd0lqyHCX\npIYMd0lqyHCXpIYMd0lqaNU0D55kE7Bpw4YN0+zGgq2/+GOH7FgXnbKHC4bj7brs7EN23H09njWP\n17hcTPNnLS2GNw6TpIYclpGkhgx3SWrIcJekhgx3SWrIcJekhgx3SWrIcJekhgx3SWrIcJekhgx3\nSWrIcJekhgx3SWrIcJekhrzl7wp0KG81LGll8pa/ktSQwzKS1JDhLkkNGe6S1JDhLkkNGe6S1JDh\nLkkNGe6S1JDhLkkNGe6S1JDhLkkNGe6S1JDhLkkNGe6S1JDhLkkNGe6S1JDhLkkNGe6S1JDhLkkN\nTTXck2xKsnV+fn6a3ZCkdnyGqiQ15LCMJDVkuEtSQ4a7JDVkuEtSQ4a7JDVkuEtSQ4a7JDVkuEtS\nQ4a7JDVkuEtSQ4a7JDVkuEtSQ4a7JDVkuEtSQ4a7JDVkuEtSQ4a7JDVkuEtSQ4a7JDVkuEtSQ4a7\nJDVkuEtSQ4a7JDVkuEtSQ4a7JDVkuEtSQ4a7JDW0apoHT7IJ2LRhw4ZpdkM6oPUXf2zJ93nRKXu4\nYIL97rrs7CU/tmbHVM/cq+q6qtqyZs2aaXZDktpxWEaSGjLcJakhw12SGjLcJakhw12SGjLcJakh\nw12SGjLcJakhw12SGjLcJakhw12SGjLcJakhw12SGjLcJakhw12SGjLcJakhw12SGjLcJakhw12S\nGjLcJakhw12SGjLcJakhw12SGjLcJakhw12SGjLcJakhw12SGjLcJakhw12SGjLcJakhw12SGjLc\nJakhw12SGjLcJakhw12SGjLcJakhw12SGjLcJakhw12SGjLcJakhw12SGjLcJakhw12SGlq11DtM\nshr4O+BHwI6qumqpjyFJenQTnbkneV+S3Ulu2af9rCS3J7kjycVD86uBD1fVG4BXLXF/JUkTmHRY\n5krgrPGGJIcBVwAvB04GzktyMnAscOew2sNL001J0sFIVU22YrIe2F5Vzx3mzwAuraqXDfOXDKve\nBXynqrYn2VZV5x5gf1uALQBr16594bZt2xZUwO7757n3BwvadEVZ+0Ta1zkLNcJs1DkLNcLS1HnK\nujUL3vbMM8/cWVUb97dsMWPu6/j/M3QYhfqLgcuBdyU5G7juQBtX1VZgK8DGjRtrbm5uQZ1451XX\n8Pabl/yjg2XnolP2tK9zFmqE2ahzFmqEpalz12vnlqYz+1jyn35VPQS8fqn3K0ma3GIuhbwbOG5s\n/tihTZI0ZYsJ988DJyY5PsnhwLnAtUvTLUnSYkx6KeTVwGeBk5LclWRzVe0BLgQ+DtwGfLCqbn38\nuipJmtREY+5Vdd4B2q8Hrl/SHkmSFm2qtx9IsinJ1vn5+Wl2Q5LamWq4V9V1VbVlzZqFX+cpSfpZ\n3jhMkhqa+Buqj2snkm8B31jg5kcD9y1hd5arWahzFmqE2ahzFmqE6df57Ko6Zn8LlkW4L0aSGw/0\n9dtOZqHOWagRZqPOWagRlnedDstIUkOGuyQ11CHct067A4fILNQ5CzXCbNQ5CzXCMq5zxY+5S5J+\nVoczd0nSPgx3SWpoRYf7AZ7huuLs7xm1SZ6W5BNJvjr8+dShPUkuH2r+UpIXTK/nByfJcUk+k+TL\nSW5N8qahvU2tSZ6Q5HNJvjjU+GdD+/FJbhhq+cBwJ1WSHDHM3zEsXz/N/h+MJIcl+UKS7cN8xxp3\nJbk5yU1JbhzaVsT7dcWG+6M8w3UlupJ9nlELXAx8qqpOBD41zMOo3hOH1xbg7w9RH5fCHuCiqjoZ\nOB343eHvrFOtPwReWlXPA04DzkpyOvA24B1VtQH4DrB5WH8zo8dSbgDeMay3UryJ0R1h9+pYI8CZ\nVXXa2PXsK+P9WlUr8gWcAXx8bP4S4JJp92sR9awHbhmbvx145jD9TOD2Yfo9wHn7W2+lvYBrgF/t\nWivwJOC/GD1+8j5g1dD+yHuX0S2zzximVw3rZdp9n6C2YxkF20uB7UC61Tj0dxdw9D5tK+L9umLP\n3Nn/M1zXTakvj4e1VXXPMP1NYO0w3aLu4Vfz5wM30KzWYbjiJmA38Anga8ADNXoGAvx0HY/UOCyf\nB446tD1ekL8B/gj4yTB/FP1qBCjgX5PsTLJlaFsR79f+T7BtoKoqSZtrVpMcCfwz8PtV9d0kjyzr\nUGtVPQycluQpwEeB50y5S0sqySuB3VW1M8nctPvzOHtJVd2d5OnAJ5L89/jC5fx+Xcln7t2f4Xpv\nkmcCDH/uHtpXdN1Jfp5RsF9VVR8ZmlvWWlUPAJ9hNETxlCR7T6bG63ikxmH5GuDbh7irB+uXgFcl\n2QVsYzQ087f0qhGAqrp7+HM3o/+oX8QKeb+u5HDv/gzXa4Hzh+nzGY1P721/3fDJ/OnA/NiviMta\nRqfo7wVuq6q/HlvUptYkxwxn7CR5IqPPFG5jFPLnDKvtW+Pe2s8BPl3DgO1yVVWXVNWxVbWe0b+7\nT1fVa2lUI0CS1UmevHca+DXgFlbK+3XaH1gs8sOOVwBfYTSm+SfT7s8i6rgauAf4MaNxus2MxiQ/\nBXwV+CTwtGHdMLpK6GvAzcDGaff/IOp8CaMxzC8BNw2vV3SqFTgV+MJQ4y3Am4f2E4DPAXcAHwKO\nGNqfMMzfMSw/Ydo1HGS9c8D2jjUO9XxxeN26N2NWyvvV2w9IUkMreVhGknQAhrskNWS4S1JDhrsk\nNWS4S1JDhrskNWS4S1JD/wd5/4LLPx1DUAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3pRZmFImSMZ",
        "colab_type": "text"
      },
      "source": [
        "So as we see the distribution considerably changes when you change the gene patter that it should find. In this case it finds less genes than before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJO7Fe8HmR1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i16hkxDJD8yh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_protein_sequences_from_fasta(fasta_filename: str) -> list:\n",
        "     return list(SeqIO.parse(fasta_filename, 'fasta'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMd9w2-gX0JO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "augustus_seq = read_protein_sequences_from_fasta('data/ref_annot_augustus.aa')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8walAf2D92e",
        "colab_type": "code",
        "outputId": "d5f2cadb-f868-44b7-e209-2c4b1bd0e1cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def save_sequences_as_fasta(sequences: list, fasta_filename: str):\n",
        "    fasta_entries = []\n",
        "    for i in range(len(sequences)):\n",
        "        if len(sequences[i]) > 20:   # shortest known protein in any organism\n",
        "            fasta_entries.append(f'>gene{i}\\n{sequences[i]}\\n')\n",
        "    with open(fasta_filename, 'w') as output_fasta:\n",
        "        output_fasta.writelines(fasta_entries)\n",
        "    print(f'INFO: Wrote {len(fasta_entries)} protein sequences')\n",
        "\n",
        "save_sequences_as_fasta(aa_sequences, 'hits.fasta')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO: Wrote 73 protein sequences\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZSzIp3nfSMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KeA0Fohh2Vj",
        "colab_type": "text"
      },
      "source": [
        "Results from augusts ploted: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzI6kzyYfSAS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "33a60994-afd9-4309-c34a-d04254196bbb"
      },
      "source": [
        "plot_protein_length_distribution(augustus_seq)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB1vqfgFFPhjtAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuF139o88X7f",
        "colab_type": "text"
      },
      "source": [
        "The plot of the results from Augustus shows a more realistic distribution of gene lenghts, considering that the average gene size in S. cerevisiae is 1.6 kb. Therefore, although my new model has a slightly better output than the first one, it is still quite far from Augustus output. It may be that it needs more training data (i.e. it may improve with training over more chromosomes) or simply that the data needs further processing before training the model. It may also be that different parameters are needed for different parts of the genome: i.e. different likelihoods of introns, exons and non-coding regions on different segments of the genome. Therefore, it could help to train on different HMM models with slightly different parameters and see if there is a better one for different parts of the genome. \n",
        "\n",
        "This could also be applied to the different \"structures\" of the genes: different sequences of exons and introns."
      ]
    }
  ]
}